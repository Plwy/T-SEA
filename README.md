# T-SEA: Transfer-based Self-Ensemble Attack on Object Detection

[**Paper**](https://arxiv.org/abs/2211.09773)
| Hao Huang, Ziyan Chen, Huanran Chen, Yongtao Wang, Kevin Zhang

An official implementation of T-SEA, and also a framework provided to achieve universal (cross model&instance) patch-based adversarial attack.


![](./figures/pipeline.png)


## Update
* 2022.11.18 - This repo is created.


## Install
### Environment
```bash
conda create -n tsea python=3.7
conda activate tsea
pip install -r requirements.txt
```

### Models & Data
Make sure you have the pre-trained detector-weight files and data prepared.
* Model: Pretrained detection model weights.
* Dataset: Images and the corresponding detection labels (for evaluation of attack) generated by the victim models.

```bash
# Download data and prepare labels in directory data/.
# A demo file tree:
├── data
    ├── INRIAPerson
        ├── Train
        ├── Test
            ├── pos # data
            ├── labels # labels
                ├── faster_rcnn-rescale-labels
                ├── ground-truth-rescale-labels
                ├── ...

# You can generate detection labels by the given model 
# or parse the annotations based on provided util scripts.
# See more details in utils/preprocesser/README.md
```
```bash
# download all model weights file in weights/.
# Run in the root proj dir.
bash ./detlib/weights/download.sh

# The weight file tree should like this.
└── detlib
    ├── base.py
    ├── HHDet
    ├── torchDet
    └── weights
        ├── setup.sh
        ├── yolov2.weights
        ├── yolov3-tiny.weights
        ├── ...
        
# To create links to the corresponding detector modules.
# Run in the root proj dir.
bash ./detlib/weights/setup.sh
```

You can download the experimental data (labels, model weights and patches) 
from [**GoogleDrive**](https://drive.google.com/drive/folders/1GzdvnLgKGiPDfitc8bIa-a76e_2Mz_Fl?usp=share_link)
| [**BaiduCloud**]().

### Run
#### Evaluation
The evaluation metrics of the **Mean Average Precision(mAP)** is provided.

```bash
# You can run the demo script directly:
bash ./scropts/preprocesser.sh
```

```bash
# Or to run the full command:
# replace the $patch_path as patch of your adversarial patch, 
# and $PROJECT_DIR as the absolute path of your project.
python evaluate.py \
-p $patch_path \
-cfg ./configs/preprocesser/coco80.yaml \
-lp $PROJECT_DIR/preprocesser/INRIAPerson/Test/labels \
-dr $PROJECT_DIR/preprocesser/INRIAPerson/Test/pos \
-s ./preprocesser/test \
-e 0 # attack class id

# For detailed supports of the arguments:
python evaluate.py -h
```
#### Training
```bash
# You can run the demo script directly:
bash ./scropts/train.sh
```

```bash
# Or to run the full command:
python train_optim.py \
-cfg=demo.yaml \
-s=./results/demo \
-n=demo # patch name & tensorboard name
```
Modify the config .yaml files for custom settings, see details in **configs/README.yaml**.


## Framework Overview
We provide a main pipeline to craft a universal adversarial patch to achieve cross-model & cross-instance attack on detectors, 
and support evaluations on given data & models.

Three individual core modules: Attack, Detlib & Utils. An overview: 
* **Detlib**
Dettlib is the detection module, which implements the input and output interfaces for individual detectors as well as an agent for unified detector calls.
Model perturbation(e.g. Shakedrop) function is achieved and implemented inside detector module.
  * **HHDet** (PyTorch) - Yolo V2, V3, V3-tiny, V4, V4tiny, V5
    * See **acknowledgements** in README.md in the main project directory.
  * **TorchDet** (PyTorch) - Faster RCNN(renet50), ssd(vgg16) & ssdlite(mobilenet v3 large)
    * Rewritten from Torch official detection models.

  * **Cutom** - You can support your custom models based on this framework. See more details in **detlib/README.md**.


* **Attack Lib**
Attack is the attack module, which implements the base attack methods and a core agent class for attack on detectors.
  * **base attack methods**
      * FGSM-based attack methods: **BIM**, **MIM** & **PGD**.
      * Optimizer: **SGD** & **Adam**.

* **Utils**
  * Config parser, data preprocessing utils
  * solver - loss fn & schedulers
  * metrics - mAP 
  * Plot - TensorBoard utils

See more details in the README.md file in the corresponding modules.


## Acknowledgements
### Detlib
* **HHDet**
  * Yolo V2 [**PyTorch implementation**](https://github.com/ayooshkathuria/pytorch-yolo2)
  | [**Paper**](https://arxiv.org/abs/1506.02640)
  | [**Page**]((https://pjreddie.com/darknet/yolo/))
  * Yolo V3 [**PyTorch implementation**](https://github.com/eriklindernoren/PyTorch-YOLOv3)
  | [**Paper**](https://arxiv.org/abs/1804.02767v1)
  | [**Page**]((https://pjreddie.com/darknet/yolo/))
  * Yolo V4 [**PyTorch implementation**](https://github.com/Tianxiaomo/pytorch-YOLOv4)
  | [**Paper**](https://arxiv.org/abs/2004.10934)
  | [**Source Code**](https://github.com/AlexeyAB/darknet)
  * Yolo V5 [**PyTorch implementation**](https://github.com/ultralytics/yolov5)
* **TorchDet**: provided by PyTorch Lib (partially rewritten)
  * FasterRCNN(resnet50 & mobilenet-v3 large), ssd(vgg16) & ssdlite(mobilenet-v3 large).


### Attack Lib
* **Reference**: Fooling automated surveillance cameras: adversarial patches to attack person detection.
[**implementation**](https://gitlab.com/EAVISE/adversarial-yolo)
| [**Paper**](http://openaccess.thecvf.com/content_CVPRW_2019/papers/CV-COPS/Thys_Fooling_Automated_Surveillance_Cameras_Adversarial_Patches_to_Attack_Person_Detection_CVPRW_2019_paper.pdf)

### Utils
* **Metrics**
  * mAP [**implementation**](https://github.com/Cartucho/mAP).
* **Plot**
  * Tensorboard.

## Contact Us
Email us if you have any problem about this work: huanghao@stu.pku.edu.cn.